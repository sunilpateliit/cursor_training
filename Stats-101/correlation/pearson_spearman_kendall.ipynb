{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "28baed1b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.figure_factory as ff\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from ydata_profiling import ProfileReport\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotly to work in notebook\n",
        "# import plotly.io as pio\n",
        "# pio.renderers.default = 'notebook'\n",
        "\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = \"browser\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7c621b81",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iris dataset shape: (150, 6)\n",
            "\n",
            "First 5 rows:\n",
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   target species  \n",
            "0       0  setosa  \n",
            "1       0  setosa  \n",
            "2       0  setosa  \n",
            "3       0  setosa  \n",
            "4       0  setosa  \n",
            "\n",
            "Dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 6 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   sepal length (cm)  150 non-null    float64\n",
            " 1   sepal width (cm)   150 non-null    float64\n",
            " 2   petal length (cm)  150 non-null    float64\n",
            " 3   petal width (cm)   150 non-null    float64\n",
            " 4   target             150 non-null    int64  \n",
            " 5   species            150 non-null    object \n",
            "dtypes: float64(4), int64(1), object(1)\n",
            "memory usage: 7.2+ KB\n",
            "None\n",
            "\n",
            "Target distribution:\n",
            "species\n",
            "setosa        50\n",
            "versicolor    50\n",
            "virginica     50\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# 1) Load iris dataset\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "df['species'] = df['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
        "\n",
        "print(\"Iris dataset shape:\", df.shape)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataset info:\")\n",
        "print(df.info())\n",
        "print(\"\\nTarget distribution:\")\n",
        "print(df['species'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "ff7eef8d",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 120410.64it/s]0:00, 235.26it/s, Describe variable: species] \n",
            "Summarize dataset: 100%|██████████| 34/34 [00:00<00:00, 67.81it/s, Completed]                                    \n",
            "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
            "Render HTML: 100%|██████████| 1/1 [00:00<00:00, 31.45it/s]\n",
            "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 89.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pandas profiling report saved as 'iris_dataset_profile.html'\n",
            "Note: Profile report saved to file. Open iris_dataset_profile.html to view the report.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 1.1) Generate pandas-profile-report and save as HTML\n",
        "try:\n",
        "    from ydata_profiling import ProfileReport\n",
        "    profile = ProfileReport(df, title=\"Iris Dataset Profiling Report\", explorative=True, correlations={\"pearson\": {\"calculate\": True}, \"spearman\": {\"calculate\": True}, \"kendall\": {\"calculate\": True}})\n",
        "    profile.to_file(\"iris_dataset_profile.html\")\n",
        "    print(\"Pandas profiling report saved as 'iris_dataset_profile.html'\")\n",
        "    print(\"Note: Profile report saved to file. Open iris_dataset_profile.html to view the report.\")\n",
        "    # Prevent automatic display that causes nbformat issues\n",
        "    del profile\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not generate profile report due to: {e}\")\n",
        "    print(\"Continuing with analysis...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "66a29571",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model trained successfully!\n",
            "Training accuracy: 1.0000\n",
            "Test accuracy: 0.9333\n"
          ]
        }
      ],
      "source": [
        "# 2) Fit a GBDT model on the raw data\n",
        "# Prepare data\n",
        "X = df.drop(['target', 'species'], axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Fit GBDT model (using XGBoost for better performance)\n",
        "gbdt_model = xgb.XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "\n",
        "gbdt_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = gbdt_model.predict(X_test)\n",
        "\n",
        "print(\"Model trained successfully!\")\n",
        "print(f\"Training accuracy: {gbdt_model.score(X_train, y_train):.4f}\")\n",
        "print(f\"Test accuracy: {gbdt_model.score(X_test, y_test):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "342bb2b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Suppress ProfileReport display to avoid nbformat issues\n",
        "# The report has been saved to iris_dataset_profile.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "61df515d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3) Plot the classification report as heatmap using plotly\n",
        "# Get classification report as dictionary\n",
        "report_dict = classification_report(y_test, y_pred, target_names=iris.target_names, output_dict=True)\n",
        "\n",
        "# Convert to DataFrame for easier plotting\n",
        "report_df = pd.DataFrame(report_dict).transpose()\n",
        "\n",
        "# Create heatmap data\n",
        "metrics = ['precision', 'recall', 'f1-score', 'support']\n",
        "classes = iris.target_names.tolist() + ['accuracy', 'macro avg', 'weighted avg']\n",
        "\n",
        "# Create the heatmap\n",
        "fig = go.Figure(data=go.Heatmap(\n",
        "    z=report_df[metrics].values,\n",
        "    x=metrics,\n",
        "    y=classes,\n",
        "    colorscale='RdYlBu_r',\n",
        "    text=np.round(report_df[metrics].values, 3),\n",
        "    texttemplate='%{text}',\n",
        "    textfont={\"size\": 12},\n",
        "    hoverongaps=False\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Classification Report Heatmap',\n",
        "    xaxis_title='Metrics',\n",
        "    yaxis_title='Classes',\n",
        "    width=800,\n",
        "    height=500,\n",
        "    font=dict(size=14)\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "cde57bf1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Importance:\n",
            "             feature  importance\n",
            "3   petal width (cm)    0.492275\n",
            "2  petal length (cm)    0.469418\n",
            "0  sepal length (cm)    0.025505\n",
            "1   sepal width (cm)    0.012802\n"
          ]
        }
      ],
      "source": [
        "# 4) Get the feature importance\n",
        "feature_importance = gbdt_model.feature_importances_\n",
        "feature_names = X.columns\n",
        "\n",
        "# Create DataFrame for feature importance\n",
        "feature_imp_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': feature_importance\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"Feature Importance:\")\n",
        "print(feature_imp_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "34c0ae30",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Importance with Cumulative Gain:\n",
            "             feature  importance  cumulative_importance  cumulative_percentage\n",
            "3   petal width (cm)    0.492275               0.492275              49.227474\n",
            "2  petal length (cm)    0.469418               0.961693              96.169312\n",
            "0  sepal length (cm)    0.025505               0.987198              98.719826\n",
            "1   sepal width (cm)    0.012802               1.000000             100.000000\n"
          ]
        }
      ],
      "source": [
        "# 5) Get the cumulative feature importance gain with features sorted in reverse of their feature importance\n",
        "# Features are already sorted in descending order of importance\n",
        "feature_imp_df['cumulative_importance'] = feature_imp_df['importance'].cumsum()\n",
        "feature_imp_df['cumulative_percentage'] = feature_imp_df['cumulative_importance'] / feature_imp_df['importance'].sum() * 100\n",
        "\n",
        "print(\"Feature Importance with Cumulative Gain:\")\n",
        "print(feature_imp_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "635289da",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6) & 7) Plot the cumulative feature importance gain with features sorted in reverse of their feature importance\n",
        "# Add markers at 80% cumulative gain\n",
        "\n",
        "# Find the 80% threshold\n",
        "threshold_80 = 80.0\n",
        "idx_80 = np.where(feature_imp_df['cumulative_percentage'] >= threshold_80)[0][0]\n",
        "\n",
        "# Create the plot\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add cumulative importance line\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=list(range(len(feature_imp_df))),\n",
        "    y=feature_imp_df['cumulative_percentage'],\n",
        "    mode='lines+markers',\n",
        "    name='Cumulative Importance',\n",
        "    line=dict(color='blue', width=3),\n",
        "    marker=dict(size=8, color='blue'),\n",
        "    hovertemplate='Feature: %{customdata}<br>Cumulative: %{y:.2f}%<extra></extra>',\n",
        "    customdata=feature_imp_df['feature']\n",
        "))\n",
        "\n",
        "# Add 80% threshold line\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=[0, len(feature_imp_df)-1],\n",
        "    y=[80, 80],\n",
        "    mode='lines',\n",
        "    name='80% Threshold',\n",
        "    line=dict(color='red', width=2, dash='dash'),\n",
        "    hovertemplate='80% Threshold<extra></extra>'\n",
        "))\n",
        "\n",
        "# Add marker at 80% point\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=[idx_80],\n",
        "    y=[feature_imp_df.iloc[idx_80]['cumulative_percentage']],\n",
        "    mode='markers',\n",
        "    name='80% Mark',\n",
        "    marker=dict(size=15, color='red', symbol='diamond'),\n",
        "    hovertemplate='80%% Mark<br>Feature: %{customdata}<br>Cumulative: %{y:.2f}%<extra></extra>',\n",
        "    customdata=[feature_imp_df.iloc[idx_80]['feature']]\n",
        "))\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Cumulative Feature Importance Gain',\n",
        "    xaxis_title='Number of Features',\n",
        "    yaxis_title='Cumulative Importance (%)',\n",
        "    width=900,\n",
        "    height=600,\n",
        "    font=dict(size=14),\n",
        "    showlegend=True,\n",
        "    xaxis=dict(tickmode='array', tickvals=list(range(len(feature_imp_df))), ticktext=feature_imp_df['feature'])\n",
        ")\n",
        "\n",
        "# Rotate x-axis labels for better readability\n",
        "fig.update_xaxes(tickangle=45)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "4e1ba150",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features after 80% cumulative importance mark (2 features):\n",
            "             feature  importance  cumulative_percentage\n",
            "0  sepal length (cm)    0.025505              98.719826\n",
            "1   sepal width (cm)    0.012802             100.000000\n"
          ]
        }
      ],
      "source": [
        "# 8) Get all features after the above mark\n",
        "less_important_features = feature_imp_df.iloc[idx_80 + 1:]\n",
        "\n",
        "print(f\"Features after 80% cumulative importance mark ({idx_80 + 1} features):\")\n",
        "print(less_important_features[['feature', 'importance', 'cumulative_percentage']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ac4ba99e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9) Display beautifully the less important features using plotly in a good white canvas and in tabular form\n",
        "# Calculate statistics for less important features\n",
        "stats_data = []\n",
        "total_rows = len(df)\n",
        "for feature in less_important_features['feature']:\n",
        "    feature_data = df[feature]\n",
        "    non_null_count = feature_data.count()\n",
        "    null_count = total_rows - non_null_count\n",
        "    null_percentage = (null_count / total_rows) * 100 if total_rows > 0 else 0\n",
        "    stats = {\n",
        "        'Feature Name': feature,\n",
        "        'Feature Importance': f\"{less_important_features[less_important_features['feature'] == feature]['importance'].values[0]:.4f}\",\n",
        "        'Non-null Values': non_null_count,\n",
        "        'Null Values %': f\"{null_percentage:.2f}%\",\n",
        "        'Mean': f\"{feature_data.mean():.4f}\",\n",
        "        'Standard Deviation': f\"{feature_data.std():.4f}\",\n",
        "        'Range': f\"{feature_data.max() - feature_data.min():.4f}\",\n",
        "        'Median': f\"{feature_data.median():.4f}\",\n",
        "        'IQR': f\"{feature_data.quantile(0.75) - feature_data.quantile(0.25):.4f}\",\n",
        "        'Q1': f\"{feature_data.quantile(0.25):.4f}\",\n",
        "        'Q3': f\"{feature_data.quantile(0.75):.4f}\"\n",
        "    }\n",
        "    stats_data.append(stats)\n",
        "\n",
        "# Create DataFrame for the table\n",
        "stats_df = pd.DataFrame(stats_data)\n",
        "\n",
        "# Create the table using plotly\n",
        "fig = go.Figure(data=[go.Table(\n",
        "    columnwidth=[200, 150, 120, 120, 100, 150, 100, 100, 100, 100, 100],\n",
        "    header=dict(\n",
        "        values=['Feature Name', 'Feature Importance', 'Non-null Values', 'Null Values %', 'Mean', 'Standard Deviation', 'Range', 'Median', 'IQR', 'Q1', 'Q3'],\n",
        "        fill_color='lightblue',\n",
        "        align='center',\n",
        "        font=dict(size=12, color='black'),\n",
        "        height=40\n",
        "    ),\n",
        "    cells=dict(\n",
        "        values=[stats_df[col] for col in stats_df.columns],\n",
        "        fill_color='white',\n",
        "        align=['left', 'center', 'center', 'center', 'center', 'center', 'center', 'center', 'center', 'center', 'center'],\n",
        "        font=dict(size=11, color='black'),\n",
        "        height=35,\n",
        "        line_color='lightgray'\n",
        "    )\n",
        ")])\n",
        "\n",
        "fig.update_layout(\n",
        "    title=dict(\n",
        "        text='Less Important Features Statistics<br><sup>Features contributing after 80% cumulative importance threshold</sup>',\n",
        "        x=0.5,\n",
        "        y=0.95,\n",
        "        xanchor='center',\n",
        "        yanchor='top',\n",
        "        font=dict(size=16, color='black')\n",
        "    ),\n",
        "    width=1200,\n",
        "    height=400,\n",
        "    margin=dict(l=20, r=20, t=80, b=20),\n",
        "    paper_bgcolor='white',\n",
        "    plot_bgcolor='white'\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dda7f18",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.13.5)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
